# Fake_News_Detection_using LSTM

Whats a Fake news?
“Fake news” is a term that has come to mean different things to different people. At its core, we are defining “fake news” as those news stories that are false: the story itself is fabricated, with no verifiable facts, sources or quotes. Sometimes these stories may be propaganda that is intentionally designed to mislead the reader, or may be designed as “clickbait” written for economic incentives (the writer profits on the number of people who click on the story). In recent years, fake news stories have proliferated via social media, in part because they are so easily and quickly shared online.

About Dataset:
This data set consists of 40000 fake and real news. Our goal is to train our model to accurately predict whether a particular piece of news is real or fake. Fake and real news data are given in two separate data sets, with each data set consisting of approximately 20000 articles.

CONTENT:

1.Import Libraries
2.Load and Check Data
3.Visualization
4.Data Cleaning
    Removal of HTML Contents
    Removal of Punctuation Marks and Special Characters
    Removal of Stopwords
    Lemmatization
5.Modeling
Train - Test Split
Tokenizing
Training LSTM Model
Analysis After Training

YOU CAN EXPLORE MORE ABOUT MODELS LIKE LSTM WHICH HAVE MEMORY RETAINING CAPACITY THE LATEST AVAILABLE NOW IS THE BERT (Bidirectional Encoder Representations from Transformers. It is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context.)
Explore more on the field of NLP.
